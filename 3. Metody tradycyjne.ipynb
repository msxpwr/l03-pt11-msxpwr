{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e1f645",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65bd4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39eb517",
   "metadata": {},
   "source": [
    "# 3. Metody tradycyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae633a5",
   "metadata": {},
   "source": [
    "## 3.1. Podział metod tradycyjnych\n",
    "\n",
    "Pierwsze zaproponowane metody uczenia reprezentacji dla danych grafowych były często metodami **transduktywnymi**. Oznacza to m.in., że raz wyuczony model nie jest w stanie wyznaczyć reprezentacji dla wcześniej nieobserwowanych wierzchołków (ang. *unseen nodes*). Implikuje to również, że cały graf musi być przetworzony przez model – nie można wyuczyć funkcji osadzania (embedding) na części grafu i następnie wyznaczać reprezentacje dla konkretnych węzłów. Modele transduktywne nie są stosowane na dużych (wielkoskalowych) grafach ze względu na wybuchającą liczbę parametrów tych modeli.\n",
    "\n",
    "Wśród tradycyjnych metod uczenia reprezentacji dla danych grafowych można wyróżnić metody oparte o:\n",
    "- błądzenia losowe (ang. *random-walks*) – np. DeepWalk, Node2vec,\n",
    "- faktoryzację macierzy (ang. *matrix factorization*) – np. HOPE, Graph Factorization, GraRep,\n",
    "- grafowe macierze Laplace'a (ang. *graph Laplacians*) – np. Laplacian Eigenmaps, Local Linear Embedding,\n",
    "- uczenie głębokie – SDNE, DNGR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20be44",
   "metadata": {},
   "source": [
    "## 3.2. Metody oparte o błądzenia losowe\n",
    "\n",
    "Omówienie wszystkich metod wykracza poza zakres kursu, ale spróbujemy uruchomić i zbadać dwie wybrane metody oparte o błądzenia losowe, mianowicie **DeepWalk** oraz **Node2vec**. Są to dwie koncepcyjnie bardzo podobne metody. Idea stojąca za tymi metodami jest oparta na modelu word2vec, znanym z dziedziny przetwarzania języka naturalnego. Word2vec wyznacza wektory reprezentacji dla słów w podanym tekście, natomiast w przypadku grafów nie mamy \"zdań\". Jak zatem zmodyfikować ten algorytm, aby mógł przetwarzać grafy? Na to pytanie po raz pierwszy próbowali odpowiedzieć autorzy metody DeepWalk. Ich rozwiązaniem było próbkowanie grafu za pomocą błądzeń losowych, z których otrzymywali sekwencje wierzchołków. Te sekwencje traktowali jako zdania, w których słowami są wierzchołki. Następnie można było bez problemu zastosować metodę word2vec.\n",
    "\n",
    "**Uwaga:** Zauważmy, że word2vec nie zwraca uwagi za \"treść\" słów, a jedynie na *współwystępowanie* słów. Można zatem stosować algorytm word2vec dla dowolnych obiektów o ile można dla nich określić koncepcję współwystępowania.\n",
    "\n",
    "Pojedyncze błądzenie losowe można opisać za pomocą algorytmu:\n",
    "1. Rozpocznij od zadanego wierzchołka $u$.\n",
    "2. Wyznacz zbiór sąsiadów: $\\mathcal{N}_u = \\{v: (u, v) \\in \\mathcal{E}\\}$.\n",
    "3. Ze zbioru sąsiadów $\\mathcal{N}_u$ wylosuj jeden element $v$ w oparciu o zadany rozkład prawdopodobieństwa.\n",
    "4. Wróć do kroku 2, ale wyznacz sąsiedztwo wierzchołka $v$. Powtarzaj dopóki nie osiągniesz zadanej długości błądzenia, bądź $\\mathcal{N}_u = \\emptyset$.\n",
    "\n",
    "W trakcie przeprowadzania błądzenia losowego zapisywane są kolejno rozważane wierzchołki w postaci sekwencji wierzchołków.\n",
    "\n",
    "\n",
    "Podsumowując, metoda DeepWalk działa w następujący sposób:\n",
    "1. Z każdego wierzchołka w grafie rozpocznij błądzenie losowe (z losowaniem sąsiadów opartym na rozkładzie jednostajnym). Wylicz kilka takich błądzeń losowych (hiperparametr metody) o zadanych długościach błądzenia (hiperparametr metody).\n",
    "2. Zainicjalizuj losowo macierz reprezentacji $\\mathbf{Z} \\in \\mathbb{R}^{|\\mathcal{V}| \\times d}$.\n",
    "3. Wyznacz pozytywne pary wierzchołków (współwystępujące w błądzeniach losowych, zastosuj kontekst / okno o zadanej długości – hiperparametr metody).\n",
    "4. Wylosuj zbiór negatywne pary wierzchołków (liczność zbioru jest hiperparametrem metody).\n",
    "5. Użyj macierzy reprezentacji oraz pozytywnych i negatywnych par, aby zoptymalizować funkcję kosztu modelu word2vec.\n",
    "\n",
    "**Uwaga:** Posiadanie (statycznej) macierzy reprezentacji, w której każdy wiersz oznacza reprezentację danego wierzchołka, powoduje, że: (a) metoda nie skaluje się dobrze dla dużych grafów, (b) jest to metoda transduktywna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c0448",
   "metadata": {},
   "source": [
    "Metoda **Node2vec** jest koncepcyjnie bardzo podobna do metody DeepWalk, z taką różnicą, że wprowadzone zostały dwa nowe hiperparametry $p$ oraz $q$, które pozwalają zmieniać zachowanie błądzeń losowych poprzez nadawanie różnych wag sąsiadom danego wierzchołka. Dobierając odpowiednio wartości tych parametrów, błądzenia mogą eksplorować graf na zasadzie przeglądu wszerz (ang. *Breadth-First Search*) albo wgłąb (ang. *Depth-First Search*). Co więcej przymując parametry $p = 1$ oraz $q = 1$ metoda Node2vec jest równoważna z metodą DeepWalk. Stąd też w bibliotece PyTorch-Geometric posiadamy tylko implementację pod nazwą Node2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1864b4",
   "metadata": {},
   "source": [
    "## 3.3. DeepWalk\n",
    "\n",
    "Uruchomimy teraz metodą DeepWalk na zbiorze Cora i zwizualizujemy otrzymane wektory reprezentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7140d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "data = Planetoid(root=\"./data/\", name=\"Cora\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code, display\n",
    "\n",
    "\n",
    "display(Code(\"random_walk_model.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_walk_model import train_random_walk_model\n",
    "\n",
    "deepwalk, train_losses = train_random_walk_model(edge_index=data.edge_index, p=1.0, q=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad87399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(range(len(train_losses)), train_losses, linestyle=\"--\", marker=\"o\")\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "from random_walk_model import get_representations\n",
    "\n",
    "\n",
    "z = get_representations(deepwalk)\n",
    "\n",
    "z_PCA = PCA(n_components=2).fit_transform(z)\n",
    "z_UMAP = UMAP(n_components=2).fit_transform(z)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "sns.scatterplot(x=z_PCA[:, 0], y=z_PCA[:, 1], hue=data.y, palette=\"Set2\", ax=axs[0])\n",
    "axs[0].set(title=\"PCA\")\n",
    "sns.scatterplot(x=z_UMAP[:, 0], y=z_UMAP[:, 1], hue=data.y, palette=\"Set2\", ax=axs[1])\n",
    "axs[1].set(title=\"UMAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3d806",
   "metadata": {},
   "source": [
    "Zaimportujemy funkcje z poprzedniego zeszytu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60061bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"2. Zadania w przetwarzaniu grafów.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd7fa2",
   "metadata": {},
   "source": [
    "## 3.4. Ewaluacja w zadaniach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c80e60",
   "metadata": {},
   "source": [
    "**Klasyfikacja węzłów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_metrics = evaluate_node_classification(data=data, z=z)\n",
    "\n",
    "print(\"-- Node classification --\")\n",
    "print(f\"Train AUC: {nc_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {nc_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a575d",
   "metadata": {},
   "source": [
    "**Predykcja krawędzi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_dataset = prepare_train_test_sets(edge_index=data.edge_index)\n",
    "\n",
    "lp_deepwalk, _ = train_random_walk_model(\n",
    "    edge_index=lp_dataset[\"train_edges_pos\"], \n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "lp_z = get_representations(lp_deepwalk)\n",
    "\n",
    "lp_metrics = evaluate_link_prediction(\n",
    "    train_edges=lp_dataset[\"train_edges\"],\n",
    "    y_train=lp_dataset[\"y_train\"],\n",
    "    test_edges=lp_dataset[\"test_edges\"],\n",
    "    y_test=lp_dataset[\"y_test\"],\n",
    "    transformation_name=\"average\",\n",
    "    z=lp_z,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"-- Link prediction --\")\n",
    "print(f\"Train AUC: {lp_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {lp_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575186e",
   "metadata": {},
   "source": [
    "**Klasyfikacja grafów**\n",
    "\n",
    "Dla zadania klasyfikacji grafów użyjemy zbioru ENZYMES, w którym każdy graf reprezentuje pojedynczy enzym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "enzymes = TUDataset(root=\"./data\", name=\"ENZYMES\")\n",
    "\n",
    "print(f\"Liczba grafów: {len(enzymes)}\")\n",
    "\n",
    "enzymes_subset, _ = train_test_split(\n",
    "    [e for e in enzymes], \n",
    "    train_size=0.1, \n",
    "    stratify=[e.y.item() for e in enzymes],\n",
    ")\n",
    "print(f\"Ograniczymy liczbę grafów do {len(enzymes_subset)}\")\n",
    "\n",
    "z = []\n",
    "\n",
    "for enzyme in tqdm(enzymes_subset, desc=\"Embedding graphs\"):\n",
    "    model, _ = train_random_walk_model(\n",
    "        edge_index=enzyme.edge_index,\n",
    "        p=1.0,\n",
    "        q=1.0,\n",
    "        num_epochs=10,\n",
    "        quiet=True,\n",
    "    )\n",
    "    \n",
    "    z.append(get_representations(model))\n",
    "        \n",
    "        \n",
    "y = torch.tensor([e.y for e in enzymes_subset])\n",
    "\n",
    "gc_metrics = evaluate_graph_classification(z, y, transformation_name=\"average\")\n",
    "\n",
    "print(\"-- Graph classification --\")\n",
    "print(f\"Train AUC: {gc_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {gc_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
